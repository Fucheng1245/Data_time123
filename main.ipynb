{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import numpy as np\n",
    "import os, sys\n",
    "import data_transforms\n",
    "\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import pickle\n",
    "import math\n",
    "import time\n",
    "import io123\n",
    "IO = io123.IO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rotation_z(pts, theta):\n",
    "    cos_theta = np.cos(theta)\n",
    "    sin_theta = np.sin(theta)\n",
    "    rotation_matrix = np.array([[cos_theta, -sin_theta, 0.0],\n",
    "                                [sin_theta, cos_theta, 0.0],\n",
    "                                [0.0, 0.0, 1.0]])\n",
    "    return pts @ rotation_matrix.T\n",
    "\n",
    "\n",
    "def rotation_y(pts, theta):\n",
    "    cos_theta = np.cos(theta)\n",
    "    sin_theta = np.sin(theta)\n",
    "    rotation_matrix = np.array([[cos_theta, 0.0, -sin_theta],\n",
    "                                [0.0, 1.0, 0.0],\n",
    "                                [sin_theta, 0.0, cos_theta]])\n",
    "    return pts @ rotation_matrix.T\n",
    "\n",
    "\n",
    "def rotation_x(pts, theta):\n",
    "    cos_theta = np.cos(theta)\n",
    "    sin_theta = np.sin(theta)\n",
    "    rotation_matrix = np.array([[1.0, 0.0, 0.0],\n",
    "                                [0.0, cos_theta, -sin_theta],\n",
    "                                [0.0, sin_theta, cos_theta]])\n",
    "    return pts @ rotation_matrix.T\n",
    "\n",
    "\n",
    "class Shapenet_ViPC(data.Dataset):\n",
    "    # def __init__(self, data_root, subset, class_choice = None):\n",
    "    def __init__(self, subset,View_align):\n",
    "        self.partial_points_path = \"/home_nfs/fucheng.niu/Data_time_test/data/Partial/%s/%s/%s.dat\"\n",
    "        self.complete_points_path = \"/home_nfs/fucheng.niu/Data_time_test/data/GT/%s/%s/%s.dat\"\n",
    "        self.view_path = \"/home_nfs/fucheng.niu/Data_time_test/data/view/%s/%s/rendering/%s.png\"\n",
    "        self.category_file = \"%s_list2.txt\"\n",
    "        self.npoints = 3500\n",
    "        self.subset = subset\n",
    "        self.category = \"all\" \n",
    "        self.cat_map = {\n",
    "            'plane':'02691156',\n",
    "            'bench': '02828884', \n",
    "            'cabinet':'02933112', \n",
    "            'car':'02958343',\n",
    "            'chair':'03001627',\n",
    "            'monitor': '03211117',\n",
    "            'lamp':'03636649',\n",
    "            'speaker': '03691459', \n",
    "            'firearm': '04090263', \n",
    "            'couch':'04256520',\n",
    "            'table':'04379243',\n",
    "            'cellphone': '04401088', \n",
    "            'watercraft':'04530566'\n",
    "        }\n",
    "        self.filelist = []\n",
    "        self.cat = []\n",
    "        self.key = []\n",
    "        self.filepath = self.category_file % self.subset\n",
    "        self.view_align = View_align\n",
    "\n",
    "        with open(self.filepath,'r') as f:\n",
    "            line = f.readline()\n",
    "            while (line):\n",
    "                self.filelist.append(line)\n",
    "                line = f.readline()\n",
    "\n",
    "        for key in self.filelist:\n",
    "            if self.category !='all':\n",
    "                if key.split(';')[0]!= self.cat_map[self.category]:\n",
    "                    continue\n",
    "            self.cat.append(key.split(';')[0])\n",
    "            self.key.append(key)\n",
    "        self.img_transforms = self._img_get_transforms(self.subset)\n",
    "\n",
    "    def _img_get_transforms(self,subset):\n",
    "        if subset == 'train':\n",
    "            transform1 = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),   \n",
    "               \n",
    "            ])\n",
    "        else:\n",
    "            transform1 = transforms.Compose([ \n",
    "                transforms.Resize(224),\n",
    "                transforms.ToTensor(),   \n",
    "            ])\n",
    "        return transform1\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        key = self.key[idx]\n",
    "        pc_part_path = self.partial_points_path % (key.split(';')[0],key.split(';')[1], key.split(';')[-1].replace('\\n', ''))\n",
    "        # pc_part_path = os.path.join(self.imcomplete_path,key.split(';')[0]+'/'+ key.split(';')[1]+'/'+key.split(';')[-1].replace('\\n', '')+'.dat')\n",
    "        \n",
    "        if self.view_align:\n",
    "            ran_key = key        \n",
    "        else:\n",
    "            ran_key = key[:-3]+str(random.randint(0,23)).rjust(2,'0')\n",
    "        \n",
    "        pc_path = self.complete_points_path % (ran_key.split(';')[0], ran_key.split(';')[1], ran_key.split(';')[-1].replace('\\n', ''))\n",
    "        # pc_path = os.path.join(self.gt_path, ran_key.split(';')[0]+'/'+ ran_key.split(';')[1]+'/'+ran_key.split(';')[-1].replace('\\n', '')+'.dat')\n",
    "        view_path = self.view_path % (ran_key.split(';')[0], ran_key.split(';')[1], ran_key.split(';')[-1].replace('\\n','')) \n",
    "        if(len(ran_key.split(';')[-1])>3):\n",
    "            print(\"bug\")\n",
    "            print(ran_key.split(';')[-1])\n",
    "            fin = ran_key.split(';')[-1][-2:]\n",
    "            interm = ran_key.split(';')[-1][:-2]\n",
    "            pc_path = self.complete_points_path % (ran_key.split(';')[0],  interm +'/', fin.replace('\\n', ''))          \n",
    "            view_path = self.view_path % (ran_key.split(';')[0]+ '/', interm , fin.replace('\\n',''))\n",
    "\n",
    "\n",
    "        views = self.img_transforms(IO.get(view_path))\n",
    "        views = views[:3,:,:]\n",
    "        # load gt points\n",
    "        with open(pc_path,'rb') as f:\n",
    "            pc = pickle.load(f).astype(np.float32)\n",
    "        # load partial points\n",
    "        with open(pc_part_path,'rb') as f:\n",
    "            pc_part = pickle.load(f).astype(np.float32)\n",
    "        # incase some item point number less than 3500 \n",
    "        if pc_part.shape[0]<self.npoints:\n",
    "            pc_part = np.repeat(pc_part,(self.npoints//pc_part.shape[0])+1,axis=0)[0:self.npoints]\n",
    "\n",
    "\n",
    "        # load the view metadata\n",
    "        image_view_id = view_path.split('/')[-1].split('.')[0]\n",
    "        part_view_id = pc_part_path.split('/')[-1].split('.')[0]\n",
    "        # print(pc_path)\n",
    "        # print(view_path)\n",
    "        # print(image_view_id)\n",
    "        # print(part_view_id)\n",
    "        view_metadata = np.loadtxt(view_path[:-6]+'rendering_metadata.txt')\n",
    "\n",
    "        theta_part = math.radians(view_metadata[int(part_view_id),0])\n",
    "        phi_part = math.radians(view_metadata[int(part_view_id),1])\n",
    "\n",
    "        theta_img = math.radians(view_metadata[int(image_view_id),0])\n",
    "        phi_img = math.radians(view_metadata[int(image_view_id),1])\n",
    "\n",
    "        pc_part = rotation_y(rotation_x(pc_part, - phi_part),np.pi + theta_part)\n",
    "        pc_part = rotation_x(rotation_y(pc_part, np.pi - theta_img), phi_img)\n",
    "\n",
    "        # normalize partial point cloud and GT to the same scale\n",
    "        gt_mean = pc.mean(axis=0) \n",
    "        pc = pc - gt_mean\n",
    "        pc_L_max = np.max(np.sqrt(np.sum(abs(pc ** 2), axis=-1)))\n",
    "        pc = pc/pc_L_max\n",
    "\n",
    "        pc_part = pc_part-gt_mean\n",
    "        pc_part = pc_part/pc_L_max\n",
    "\n",
    "        return ran_key.split(';')[0], ran_key.split(';')[1], (torch.from_numpy(pc_part).float(), torch.from_numpy(pc).float(),views.float()),torch.tensor(0), torch.tensor(0)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.key)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Shapenet_ViPC(\"train\",True)\n",
    "test_data = Shapenet_ViPC(\"test\",True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "shuffle = 1\n",
    "num_workers = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_init_fn(worker_id):\n",
    "    np.random.seed(np.random.get_state()[1][0] + worker_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(train_data, batch_size=bs,\n",
    "                                                    shuffle = shuffle, \n",
    "                                                    drop_last = True,\n",
    "                                                    num_workers = num_workers,\n",
    "                                                    worker_init_fn=worker_init_fn,\n",
    "                                                    pin_memory = True)\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(test_data, batch_size=bs,\n",
    "                                                    shuffle = shuffle, \n",
    "                                                    drop_last = False,\n",
    "                                                    num_workers = num_workers,\n",
    "                                                    worker_init_fn=worker_init_fn,\n",
    "                                                    pin_memory = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 0/10][Batch 1/3] DataTime = 9.044 (s)\n",
      "[Epoch 0/10][Batch 2/3] DataTime = 0.502 (s)\n",
      "[Epoch 0/10][Batch 3/3] DataTime = 0.530 (s)\n",
      "[Epoch 1/10][Batch 1/3] DataTime = 0.653 (s)\n",
      "[Epoch 1/10][Batch 2/3] DataTime = 0.514 (s)\n",
      "[Epoch 1/10][Batch 3/3] DataTime = 0.585 (s)\n",
      "[Epoch 2/10][Batch 1/3] DataTime = 0.652 (s)\n",
      "[Epoch 2/10][Batch 2/3] DataTime = 0.607 (s)\n",
      "[Epoch 2/10][Batch 3/3] DataTime = 0.708 (s)\n",
      "[Epoch 3/10][Batch 1/3] DataTime = 0.630 (s)\n",
      "[Epoch 3/10][Batch 2/3] DataTime = 0.431 (s)\n",
      "[Epoch 3/10][Batch 3/3] DataTime = 0.446 (s)\n",
      "[Epoch 4/10][Batch 1/3] DataTime = 0.342 (s)\n",
      "[Epoch 4/10][Batch 2/3] DataTime = 0.248 (s)\n",
      "[Epoch 4/10][Batch 3/3] DataTime = 0.247 (s)\n",
      "[Epoch 5/10][Batch 1/3] DataTime = 0.362 (s)\n",
      "[Epoch 5/10][Batch 2/3] DataTime = 0.246 (s)\n",
      "[Epoch 5/10][Batch 3/3] DataTime = 0.249 (s)\n",
      "[Epoch 6/10][Batch 1/3] DataTime = 0.352 (s)\n",
      "[Epoch 6/10][Batch 2/3] DataTime = 0.213 (s)\n",
      "[Epoch 6/10][Batch 3/3] DataTime = 0.230 (s)\n",
      "[Epoch 7/10][Batch 1/3] DataTime = 0.355 (s)\n",
      "[Epoch 7/10][Batch 2/3] DataTime = 0.247 (s)\n",
      "[Epoch 7/10][Batch 3/3] DataTime = 0.254 (s)\n",
      "[Epoch 8/10][Batch 1/3] DataTime = 0.314 (s)\n",
      "[Epoch 8/10][Batch 2/3] DataTime = 0.255 (s)\n",
      "[Epoch 8/10][Batch 3/3] DataTime = 0.253 (s)\n",
      "[Epoch 9/10][Batch 1/3] DataTime = 0.347 (s)\n",
      "[Epoch 9/10][Batch 2/3] DataTime = 0.247 (s)\n",
      "[Epoch 9/10][Batch 3/3] DataTime = 0.240 (s)\n",
      "[Epoch 10/10][Batch 1/3] DataTime = 0.297 (s)\n",
      "[Epoch 10/10][Batch 2/3] DataTime = 0.248 (s)\n",
      "[Epoch 10/10][Batch 3/3] DataTime = 0.249 (s)\n"
     ]
    }
   ],
   "source": [
    "max_epoch =10\n",
    "\n",
    "all_data_times = []\n",
    "\n",
    "for epoch in range(0, max_epoch + 1):\n",
    "    batch_start_time = time.time()\n",
    "    n_batches = len(train_dataloader)\n",
    "    epoch_data_times = []\n",
    "    for idx, (taxonomy_ids, model_ids, data,_,_) in enumerate(train_dataloader):\n",
    "            # print(\"data2:\",data[0].shape)\n",
    "            data_time= time.time() - batch_start_time \n",
    "            \n",
    "\n",
    "            print('[Epoch %d/%d][Batch %d/%d] DataTime = %.3f (s)' %\n",
    "                            (epoch, max_epoch, idx + 1, n_batches, data_time,))\n",
    "            epoch_data_times.append(data_time)\n",
    "            batch_start_time = time.time()\n",
    "all_data_times.extend(epoch_data_times)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4906/2307280321.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data_times\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Data Time per Batch\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmean_data_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data_times\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxhline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_data_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinestyle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Mean Data Time = {mean_data_time:.3f} s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(all_data_times, label=\"Data Time per Batch\", color='b')\n",
    "mean_data_time = sum(all_data_times) / len(all_data_times)\n",
    "plt.axhline(mean_data_time, color='r', linestyle='--', label=f\"Mean Data Time = {mean_data_time:.3f} s\")\n",
    "\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Data Time (s)')\n",
    "plt.title('Data Time per Batch across Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XMF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
